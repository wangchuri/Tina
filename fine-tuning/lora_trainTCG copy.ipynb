{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设备加载 ，如果有安装cuda，则使用cuda，否则使用cpu，运行后会显示使用了什么设备\n",
    "import torch\n",
    "import os\n",
    "from peft import LoraConfig ,get_peft_model\n",
    "from transformers import Qwen2VLForConditionalGeneration,generation\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from transformers.data.data_collator import DataCollatorForSeq2Seq\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "BASEDIR = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分词器加载\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_dir,\n",
    "    use_fast=False, \n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#模型加载\n",
    "#模型路径\n",
    "model_dir = os.path.join(BASEDIR,'model/Qwen2-VL-2B-Instruct')\n",
    "print(model_dir)\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    model_dir,\n",
    "\n",
    "    device_map =device,#使用cuda设备\n",
    "    \n",
    "    torch_dtype=torch.bfloat16#使用半精度浮点数\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用模型\n",
    "\n",
    "\n",
    "input_text = input(\"请输入文字：\")\n",
    "input_text = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "output = model.generate(input_text, max_length=50, num_beams=5, early_stopping=True)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看模型有哪些部分\n",
    "for name, module in model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载lora配置\n",
    "config = LoraConfig(\n",
    "    r=8,                     # 增大秩\n",
    "    lora_alpha=16,          # 增大 alpha\n",
    "    lora_dropout=0.2,       # 增大 dropout 率以防止过拟合\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"fc1\", \"fc2\"]  # 扩展到 MLP 层\n",
    ")\n",
    "\n",
    "#将模型和lora配置结合\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#检查分词器\n",
    "sents = [\n",
    "    '你站在桥上看风景',\n",
    "    '看风景的人在楼上看你',\n",
    "    '明月装饰了你的窗子',\n",
    "    '你装饰了别人的梦',\n",
    "]\n",
    "out = tokenizer.batch_encode_plus(\n",
    "    batch_text_or_text_pairs = [(sents[0],sents[1]),(sents[2],sents[3])],\n",
    "    text_pair = sents[1],\n",
    "    truncation = True,\n",
    "    padding = 'max_length',\n",
    "    add_special_tokens =True,\n",
    "    max_length = 25,\n",
    "    return_tensors = None,\n",
    "    return_token_type_ids = True,\n",
    "    return_attention_mask = True,\n",
    "    return_special_tokens_mask = True,\n",
    "    # return_offsets_mapping = True,\n",
    "    return_length = True,\n",
    "    \n",
    ")\n",
    "for k , v in out.items():\n",
    "    print(k,':',v)\n",
    "print(tokenizer.decode(out['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(BASEDIR,\"train_TCG/train.jsonl\")\n",
    "print(dataset_dir)\n",
    "\n",
    "def process(data):\n",
    "    '''\n",
    "    将传入数据编码，\n",
    "    '''\n",
    "    MAX_LENGTH = 384\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction = tokenizer(\n",
    "        f\"<| im_start |>system\\n{data['instruction']}<|im_end|>\\n <|im_start|>user\\n {data['input']} <|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "        add_special_tokens=False,\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "        )\n",
    "    response = tokenizer(f\"{data['output']} <|im_end|>\", add_special_tokens=False)\n",
    "    input_ids = instruction['input_ids']+response['input_ids']+[tokenizer.pad_token_id]\n",
    "    attention_mask = instruction['attention_mask']+response['attention_mask']+[1]\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\":input_ids,\n",
    "        \"attention_mask\":attention_mask,\n",
    "        \"labels\":labels\n",
    "    }\n",
    "\n",
    "datadf = pd.read_json(dataset_dir,lines=True)\n",
    "datads = Dataset.from_pandas(datadf)\n",
    "train_data = datads.map(\n",
    "    process,\n",
    "    remove_columns=datads.column_names\n",
    "    )\n",
    "\n",
    "# with open(data_path,'r',encoding='utf-8') as f:\n",
    "#     for line in f:\n",
    "#         instruct = f[\"instruction\"]\n",
    "#         input = f['input']\n",
    "#         output = f['output']\n",
    "\n",
    "#这上面的是针对jsonl文件的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看数据集\n",
    "print(train_data['input_ids'])\n",
    "decode_data = tokenizer.batch_decode(train_data['input_ids'][:10], skip_special_tokens=True)\n",
    "print(decode_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载训练器\n",
    "\n",
    "#训练器超参数\n",
    "args = TrainingArguments(\n",
    "    output_dir='./output_dir',\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=2,\n",
    "    save_steps=100,\n",
    "    learning_rate=1e-4,\n",
    "    save_on_each_node=True,\n",
    "    gradient_checkpointing=True,\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_data,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "      param.requires_grad = True\n",
    "      print(param.requires_grad)\n",
    "    # param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型使用，前面已经导入模型的情况下\n",
    "\n",
    "\n",
    "model_dir_trained = os.path.join(BASEDIR,\"output_dir/checkpoint-4\")\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    model_dir_trained,\n",
    "\n",
    "    device_map =device,#使用cuda设备\n",
    "    \n",
    "    torch_dtype=torch.bfloat16#使用半精度浮点数\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_text = input(\"请输入文字：\")\n",
    "input_text = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "output = model.generate(input_text, max_length=50, num_beams=5, early_stopping=True)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
